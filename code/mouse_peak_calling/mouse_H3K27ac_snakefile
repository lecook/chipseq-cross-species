#! /usr/bin/env python

## Author: Laura E Cook, University of Melbourne
## Purpose: ChIP-seq pipeline for histone marks
## This workflow only works for single-end reads
    # 1. FastQC on raw reads
    # 2. Alignment (downloaded from ENCODE)
    # 3. Filtering
    # 4. Alignment QC & Library Complexity
    # 5. deepTools
    # 7. cross correlation (SPP)
    # 8. Call narrow peaks (MACS2)
    # 9. Create consensus peaksets


configfile: "code/configs/config_H3K27ac.yaml"
# Contains sample and genome information
# calls the SRR.txt file that contains the samples as either IP or control

import csv
import os

IPS = []
INPUTS = []
MARK = []
STAGE = []

with open(config['SAMPLES'], "r") as f:
    reader = csv.reader(f, delimiter = ",")
    header = next(reader)
    for row in reader:
        IPS.append(row[3])
        INPUTS.append(row[4])
        MARK.append(row[1])
        STAGE.append(row[2])
f.close()

## multiple samples may use the same control input files
unique_inputs = list(set(INPUTS))
unique_marks = list(set(MARK))
unique_stages = list(set(STAGE))

## combine all samples
all_samples = IPS + INPUTS
print(all_samples)
# ===============================================================================================
#        Output targets
# ===============================================================================================

rule all:
    input:
        expand("output/bam_files/{sample}_{stage}_{mark}_q30.sorted.bam", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.bam", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/bam_files/{sample}_{stage}_{mark}_q30.sorted.dedup.bam", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bai", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/qc/{sample}_{stage}_{mark}.dedup.flagstat.qc", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/qc/{sample}_{stage}_{mark}.dupmark.flagstat.qc", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/qc/{sample}_{stage}_{mark}.q30.flagstat.qc", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/qc/{sample}_{stage}_{mark}.unfiltered.flagstat.qc", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/qc/{sample}_{stage}_{mark}.downSampled.flagstat.qc", zip, sample=all_samples, stage=STAGE, mark=MARK),
        "output/bam_files/E10.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        "output/bam_files/E11.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        "output/bam_files/E12.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        "output/bam_files/E13.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        "output/bam_files/E14.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        "output/bam_files/E15.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        "output/bam_files/input_E10.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        "output/bam_files/input_E11.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        "output/bam_files/input_E12.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        "output/bam_files/input_E13.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        "output/bam_files/input_E14.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        "output/bam_files/input_E15.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        "output/logs/E10.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/E11.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/E12.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/E13.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/E14.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/E15.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/input_E10.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/input_E11.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/input_E12.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/input_E13.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/input_E14.5_H3K27ac_downSampled.mergeBAM",
        "output/logs/input_E15.5_H3K27ac_downSampled.mergeBAM",
        "output/qc/H3K27ac_multibamsum_mouse.npz",
        "output/qc/H3K27ac_multibamsum_mouse.tab",
        "docs/H3K27ac_pearsoncor_multibamsum_mouse.pdf",
        "output/qc/H3K27ac_pearsoncor_multibamsum_matrix_mouse.txt",
        expand("output/qc/{sample}_{stage}_{mark}.SeqDepthNorm.bw", zip, sample=all_samples, stage=STAGE, mark=MARK),
        "docs/H3K27ac_multiBAM_fingerprint_mouse.pdf",
        "output/qc/H3K27ac_multiBAM_fingerprint_metrics_mouse.txt",
        "output/qc/H3K27ac_multiBAM_fingerprint_rawcounts_mouse.txt",
        "docs/H3K27ac_plot_coverage_mouse.pdf",
        "output/qc/H3K27ac_plot_coverage_rawcounts_mouse.tab",
        expand("output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.tmp.bam", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/logs/{sample}_{stage}_{mark}.pbc.sort", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/qc/{sample}_{stage}_{mark}.pbc.qc", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/qc/{sample}_{stage}_{mark}_filt_15Mreads.SE.cc.qc",zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/qc/{sample}_{stage}_{mark}_filt_15Mreads.SE.cc.plot.pdf", zip, sample=all_samples, stage=STAGE, mark=MARK),
        expand("output/peaks/{case}_vs_{control}_{stage}_{mark}_macs2_downSampled_peaks.narrowPeak", zip, case=IPS, control=INPUTS, stage=STAGE, mark=MARK),
        expand("output/peaks/{case}_vs_{control}_{stage}_{mark}_macs2_downSampled_peaks.xls", zip, case=IPS, control=INPUTS, stage=STAGE, mark=MARK),
        expand("output/peaks/{case}_vs_{control}_{stage}_{mark}_macs2_downSampled_summits.bed", zip, case=IPS, control=INPUTS, stage=STAGE, mark=MARK),
        expand("output/logs/{case}_vs_{control}_{stage}_{mark}_call_peaks_macs2_downSampled.log", zip, case=IPS, control=INPUTS, stage=STAGE, mark=MARK),
        expand("output/bam_files/{case}_{stage}_{mark}_downSampled_q30.sorted.dedup.bed", zip, case=IPS, stage=STAGE, mark=MARK),
        expand("output/logs/{case}_{stage}_{mark}_downSampled.bamToBed", zip, case=IPS, stage=STAGE, mark=MARK),
        expand("output/qc/{case}_vs_{control}_{stage}_{mark}_downSampled.frip.txt", zip, case=IPS, control=INPUTS, stage=STAGE, mark=MARK),
        "output/peaks/H3K27ac_E10.5_overlap.narrowPeak",
        "output/peaks/H3K27ac_E11.5_overlap.narrowPeak",
        "output/peaks/H3K27ac_E12.5_overlap.narrowPeak",
        "output/peaks/H3K27ac_E13.5_overlap.narrowPeak",
        "output/peaks/H3K27ac_E14.5_overlap.narrowPeak",
        "output/peaks/H3K27ac_E15.5_overlap.narrowPeak",
        "output/qc/H3K27ac_E10.5_overlap.frip",
        "output/qc/H3K27ac_E11.5_overlap.frip",
        "output/qc/H3K27ac_E12.5_overlap.frip",
        "output/qc/H3K27ac_E13.5_overlap.frip",
        "output/qc/H3K27ac_E14.5_overlap.frip",
        "output/qc/H3K27ac_E15.5_overlap.frip"

# ===============================================================================================
#  1. FASTQC
# ===============================================================================================

## Done separately because fastq and BAM files don't share file prefixes so it becomes very messy
# without renaming everything

# ===============================================================================================
#  2. ALIGNMENT
#   > ENCODE alignment downloaded from ENCODE database
# ===============================================================================================

## Singled-end 36-50nt reads
## bwa-aln used for aligning reads to the mouse genome (mm10 assembly)
## Alignment command: bwa-aln -q 5 -l 32 -k 2 <reference_file> <read_file>
## bwa version version 0.7.7

## -q = parameter for read trimming
## -l = read length
## -k = Maximum edit distance in the seed

# ===============================================================================================
#  4. FILTERING
#   > remove unmapped, mate unmapped
#   > remove low MAPQ reads (-q 30)
#   > -F 1804
#           -Read unmapped
#           -Mate unmapped
#           -Not primary alignment
#           -Read fails platform/vendor quality checks
#           -Read is PCR or optical duplicate
#   > mark duplicates & remove duplicates (picard)
#   > re-filter, sort and index final BAM
# ===============================================================================================

rule filter:
    input:
        "output/bam_files/{sample}_{stage}_{mark}.bam"
    output:
        "output/bam_files/{sample}_{stage}_{mark}_q30.sorted.bam"
    log:
        "output/logs/{sample}_{stage}_{mark}.filter"
    shell:
        "samtools view -b -F 1804 -q 30 {input} | samtools sort -o {output} - 2> {log}"

rule markDups:
    input:
        "output/bam_files/{sample}_{stage}_{mark}_q30.sorted.bam"
    output:
        bam="output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.bam",
        dupQC="output/bam_files/{sample}_{stage}_{mark}.dupmark.qc"
    log:
        "output/logs/{sample}_{stage}_{mark}.dupmark"
    shell:
        "picard MarkDuplicates I={input} O={output.bam} METRICS_FILE={output.dupQC} REMOVE_DUPLICATES=false ASSUME_SORTED=true 2> {log}"

rule dedup:
    input:
        "output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.bam"
    output:
        "output/bam_files/{sample}_{stage}_{mark}_q30.sorted.dedup.bam"
    log:
        "output/logs/{sample}_{stage}_{mark}.dedup"
    shell:
        "samtools view -F 1804 -b {input} | samtools sort -o {output} - 2> {log}"

# rule normalise10Mreads:
#     input:
#         "output/bam_files/{sample}_{stage}_{mark}_q30.sorted.dedup.bam"
#     output:
#         "output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam"
#     params:
#         reads=10000000
#     shell:
#         """frac="samtools idxstats {input} | cut -f3 | awk -v ct={params.reads} 'BEGIN {{total=0}} {{total += $1}} END {{print ct/total}}'" \
#         samtools view -bs $frac {input} > {output}"""

rule indexBam:
    input:
        "output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam"
    output:
        "output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bai"
    log:
        "output/logs/{sample}_{stage}_{mark}_downSampled.indexBam"
    shell:
        "samtools index {input} {output} 2> {log}"

rule mergeBAMreplicates:
    input:
        E10 = ["output/bam_files/ENCFF213EBC_E10.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF548BRR_E10.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E11 = ["output/bam_files/ENCFF512SFE_E11.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF515PKL_E11.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E12 = ["output/bam_files/ENCFF394TZN_E12.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF011NFM_E12.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E13 = ["output/bam_files/ENCFF194ORC_E13.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF290ZNF_E13.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E14 = ["output/bam_files/ENCFF327VAO_E14.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF902HAR_E14.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E15 = ["output/bam_files/ENCFF584JFB_E15.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF707WKL_E15.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E10C = ["output/bam_files/ENCFF157KEH_E10.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF825AVI_E10.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E11C = ["output/bam_files/ENCFF184CUE_E11.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF376FGM_E11.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E12C = ["output/bam_files/ENCFF203JQV_E12.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF058AUT_E12.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E13C = ["output/bam_files/ENCFF117QRC_E13.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF248PGK_E13.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E14C = ["output/bam_files/ENCFF784ORI_E14.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF002HZV_E14.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
        E15C = ["output/bam_files/ENCFF727QTS_E15.5_H3K27ac_downSampled_q30.sorted.dedup.bam", "output/bam_files/ENCFF182XFG_E15.5_H3K27ac_downSampled_q30.sorted.dedup.bam"],
    output:
        E10 = "output/bam_files/E10.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E11 = "output/bam_files/E11.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E12 = "output/bam_files/E12.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E13 = "output/bam_files/E13.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E14 = "output/bam_files/E14.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E15 = "output/bam_files/E15.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E10C = "output/bam_files/input_E10.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E11C = "output/bam_files/input_E11.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E12C = "output/bam_files/input_E12.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E13C = "output/bam_files/input_E13.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E14C = "output/bam_files/input_E14.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E15C = "output/bam_files/input_E15.5_H3K27ac_downSampled_q30.sorted.dedup.bam"
    log:
        E10 = "output/logs/E10.5_H3K27ac_downSampled.mergeBAM",
        E11 = "output/logs/E11.5_H3K27ac_downSampled.mergeBAM",
        E12 = "output/logs/E12.5_H3K27ac_downSampled.mergeBAM",
        E13 = "output/logs/E13.5_H3K27ac_downSampled.mergeBAM",
        E14 = "output/logs/E14.5_H3K27ac_downSampled.mergeBAM",
        E15 = "output/logs/E15.5_H3K27ac_downSampled.mergeBAM",
        E10C = "output/logs/input_E10.5_H3K27ac_downSampled.mergeBAM",
        E11C = "output/logs/input_E11.5_H3K27ac_downSampled.mergeBAM",
        E12C = "output/logs/input_E12.5_H3K27ac_downSampled.mergeBAM",
        E13C = "output/logs/input_E13.5_H3K27ac_downSampled.mergeBAM",
        E14C = "output/logs/input_E14.5_H3K27ac_downSampled.mergeBAM",
        E15C = "output/logs/input_E15.5_H3K27ac_downSampled.mergeBAM"
    run:
        shell("samtools merge {output.E10} {input.E10} 2> {log.E10}")
        shell("samtools merge {output.E11} {input.E11} 2> {log.E11}")
        shell("samtools merge {output.E12} {input.E12} 2> {log.E12}")
        shell("samtools merge {output.E13} {input.E13} 2> {log.E13}")
        shell("samtools merge {output.E14} {input.E14} 2> {log.E14}")
        shell("samtools merge {output.E15} {input.E15} 2> {log.E15}")
        shell("samtools merge {output.E10C} {input.E10C} 2> {log.E10C}")
        shell("samtools merge {output.E11C} {input.E11C} 2> {log.E11C}")
        shell("samtools merge {output.E12C} {input.E12C} 2> {log.E12C}")
        shell("samtools merge {output.E13C} {input.E13C} 2> {log.E13C}")
        shell("samtools merge {output.E14C} {input.E14C} 2> {log.E14C}")
        shell("samtools merge {output.E15C} {input.E15C} 2> {log.E15C}")


# ===============================================================================================
#  4. ALIGNMENT QC
#   > SAMtools flagstat statistics
#   > CollectMultipleMetrics (picard)
#   > Compute Library Complexity (PreSeq)
# ===============================================================================================

rule mappingStats:
    input:
        a="output/bam_files/{sample}_{stage}_{mark}_q30.sorted.dedup.bam",
        b="output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.bam",
        c="output/bam_files/{sample}_{stage}_{mark}_q30.sorted.bam",
        d="output/bam_files/{sample}_{stage}_{mark}.bam", 
        e="output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam"
    output:
        a="output/qc/{sample}_{stage}_{mark}.dedup.flagstat.qc",
        b="output/qc/{sample}_{stage}_{mark}.dupmark.flagstat.qc",
        c="output/qc/{sample}_{stage}_{mark}.q30.flagstat.qc",
        d="output/qc/{sample}_{stage}_{mark}.unfiltered.flagstat.qc",
        e="output/qc/{sample}_{stage}_{mark}.downSampled.flagstat.qc"
    run:
        shell("samtools flagstat {input.a} > {output.a}")
        shell("samtools flagstat {input.b} > {output.b}")
        shell("samtools flagstat {input.c} > {output.c}")
        shell("samtools flagstat {input.d} > {output.d}")
        shell("samtools flagstat {input.e} > {output.e}")

rule sort_name:
     input:
         "output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.bam"
     output:
         tmp = "output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.tmp.bam"
     log:
         "output/logs/{sample}_{stage}_{mark}.pbc.sort"
     run:
         shell("samtools sort -n {input} -o {output.tmp} 2> {log}")

rule estimate_lib_complexity:
     input:
         "output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.tmp.bam"
     output:
         qc = "output/qc/{sample}_{stage}_{mark}.pbc.qc",
     log:
         "output/logs/{sample}_{stage}_{mark}.pbc"
     shell:
        """bedtools bamtobed -i {input} | grep -v 'chrM' \
        | awk 'BEGIN{{OFS="\\t"}}{{print $1,$2,$3,$6}}' \
        | sort | uniq -c \
        | awk 'BEGIN{{mt=0;m0=0;m1=0;m2=0}} ($1==1){{m1=m1+1}} ($1==2){{m2=m2+1}} \
        {{m0=m0+1}} {{mt=mt+$1}} END{{printf "%d\\t%d\\t%d\\t%d\\t%f\\t%f\\t%f\\n" ,mt,m0,m1,m2,m0/mt,m1/m0,m1/m2}}' \
        > {output.qc}"""


## convert to bed
## print read 1 scaffold, read 1 start coordinate, read 2 scaffold, read 2 end coordinate, strand read 1, strand read 2
## remove mitochondrial genome
## sort by position and obtain uniq reads
## Format of file
## TotalReadPairs [tab] DistinctReadPairs [tab] OneReadPair [tab] TwoReadPairs [tab] NRF=Distinct/Total [tab] PBC1=OnePair/Distinct [tab] PBC2=OnePair/TwoPair


# ===============================================================================================
#  5. deepTools
#   > multiBAMsummary
#   > plotCorrelation
#   > plotFingerprint
#   > bamCoverage (read depth normalised bigWig files)
# ===============================================================================================

rule deeptools_summary:
    input:
        expand(["output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam"], zip, sample=all_samples, stage=STAGE, mark=MARK)
    output:
        sum="output/qc/H3K27ac_multibamsum_mouse.npz",
        counts="output/qc/H3K27ac_multibamsum_mouse.tab"
    threads: 32
    log:
        "output/logs/H3K27ac_multisummary_mouse.deepTools"
    shell:
        " multiBamSummary bins \
        -p {threads} \
        -b {input} \
        --centerReads \
        -out {output.sum} \
        --outRawCounts {output.counts} 2> {log}"

rule deeptools_correlation:
    input: "output/qc/H3K27ac_multibamsum_mouse.npz"
    output:
        fig="docs/H3K27ac_pearsoncor_multibamsum_mouse.pdf",
        matrix="output/qc/H3K27ac_pearsoncor_multibamsum_matrix_mouse.txt"
    log:
        "output/logs/H3K27ac_correlation_mouse.deepTools"
    shell:
        "plotCorrelation \
        --corData {input} \
        --plotFile {output.fig} \
        --outFileCorMatrix {output.matrix} \
        --corMethod pearson \
        --whatToPlot heatmap \
        --skipZeros \
        --plotNumbers \
        --colorMap RdYlBu 2> {log}"

rule deeptools_coverage:
    input:
        bam = "output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam",
        bai = "output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bai"
    output:
        "output/qc/{sample}_{stage}_{mark}.SeqDepthNorm.bw"
    log:
        "output/logs/{sample}_{stage}_{mark}_coverage.deepTools"
    shell:
        "bamCoverage --bam {input.bam} --binSize 10 --normalizeUsing RPGC --effectiveGenomeSize 2308125349 --numberOfProcessors 4 -o {output} 2> {log}"

rule deeptools_fingerprint:
    input:
        bam = expand(["output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam"], zip, sample=all_samples, stage=STAGE, mark = MARK),
        bai = expand(["output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bai"], zip, sample=all_samples, stage=STAGE, mark = MARK)
    output:
        fig="docs/H3K27ac_multiBAM_fingerprint_mouse.pdf",
        metrics="output/qc/H3K27ac_multiBAM_fingerprint_metrics_mouse.txt",
        rawcounts="output/qc/H3K27ac_multiBAM_fingerprint_rawcounts_mouse.txt"
    threads: 32
    log:
        "output/logs/H3K27ac_fingerprint_mouse.deepTools"
    shell:
        "plotFingerprint -p {threads} \
        -b {input.bam} \
        --plotFile {output.fig} \
        --outQualityMetrics {output.metrics} \
        --outRawCounts {output.rawcounts} \
        --minMappingQuality 20 \
        --skipZeros \
        --centerReads 2> {log}"

rule deeptools_plotCoverage:
    input:
        bam = expand(["output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam"], zip, sample=all_samples, stage=STAGE, mark=MARK),
        bai = expand(["output/bam_files/{sample}_{stage}_{mark}_downSampled_q30.sorted.dedup.bai"], zip, sample=all_samples, stage=STAGE, mark=MARK)
    output:
        fig="docs/H3K27ac_plot_coverage_mouse.pdf",
        rawcounts="output/qc/H3K27ac_plot_coverage_rawcounts_mouse.tab"
    log:
        "output/logs/H3K27ac_plotCoverage_mouse.deepTools"
    shell:
        "plotCoverage --bamfiles {input.bam} --plotFile {output.fig} \
        -n 1000000 \
        --outRawCounts {output.rawcounts} \
        --ignoreDuplicates 2> {log}"


# ===============================================================================================
#  6. Cross-correlation scores - following ENCODE code
# ===============================================================================================

rule bamtobed_crossC:
    input:
        "output/bam_files/{sample}_{stage}_{mark}_q30.dupmark.bam"
    output:
        tagAlign = "output/bam_files/{sample}_{stage}_{mark}_q30_SE.tagAlign.gz"
    shell:
        """
        bedtools bamtobed -i {input} | \
        awk 'BEGIN{{OFS="\\t"}}{{$4='N';$5='1000';print $0}}' |\
        gzip -nc > {output.tagAlign}
        """

## Subsample 15 million reads for cross-correlation analysis
## Estimate read length from first 100 reads
rule subsample_aligned_reads:
    input:
        "output/bam_files/{sample}_{stage}_{mark}_q30_SE.tagAlign.gz"
    output:
        subsample = "output/bam_files/{sample}_{stage}_{mark}.filt.sample.15Mreads.SE.tagAlign.gz",
        tmp = "output/bam_files/{sample}_{stage}_{mark}_R1_trimmed_q30_SE.tagAlign.tmp"
    params:
        nreads= 15000000
    run:
        shell("""zcat {input} | shuf -n {params.nreads} --random-source=<(openssl enc -aes-256-ctr -pass pass:$(zcat -f {input} | wc -c) -nosalt </dev/zero 2>/dev/null) | gzip -nc > {output.subsample}""")
        shell("zcat {input} > {output.tmp}")

# Determine exclusion range for fragment length estimation.
## From bamPEFragmentSize (deepTools) average fragment length is ~220bp
## See bamPEFragmentSize.histogram.pdf
# Use a fixed lowerbound at -500.
# Upperbound E
#EXCLUSION_RANGE_MAX is
#   Histone ChIP-seq:  max(read_len + 10, 100)
# lowerbound is fixed at 500 for both


rule cross_correlation_SSP:
    input:
        "output/bam_files/{sample}_{stage}_{mark}.filt.sample.15Mreads.SE.tagAlign.gz"
    output:
        CC_SCORES_FILE="output/qc/{sample}_{stage}_{mark}_filt_15Mreads.SE.cc.qc",
        CC_PLOT_FILE="output/qc/{sample}_{stage}_{mark}_filt_15Mreads.SE.cc.plot.pdf"
    log:
        "output/logs/{sample}_{stage}_{mark}_filt_15Mreads.SE.spp.log"
    params:
        EXCLUSION_RANGE_MIN=-500,
        EXCLUSION_RANGE_MAX=85
    shell:
        "Rscript code/run_spp.R -c={input} -savp={output.CC_PLOT_FILE} -out={output.CC_SCORES_FILE} -x={params.EXCLUSION_RANGE_MIN}:{params.EXCLUSION_RANGE_MAX} 2> {log}"


# CC_SCORE FILE format
# Filename <tab> numReads <tab> estFragLen <tab> corr_estFragLen <tab> PhantomPeak <tab> corr_phantomPeak <tab> argmin_corr <tab> min_corr <tab> phantomPeakCoef <tab> relPhantomPeakCoef <tab> QualityTag


# ===============================================================================================
#  7. Call peaks (MACS2)
# ===============================================================================================

rule call_peaks_macs2:
    input:
        control = "output/bam_files/{control}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam",
        case = "output/bam_files/{case}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam"
    output:
        "output/peaks/{case}_vs_{control}_{stage}_{mark}_macs2_downSampled_peaks.xls",
        "output/peaks/{case}_vs_{control}_{stage}_{mark}_macs2_downSampled_summits.bed",
        "output/peaks/{case}_vs_{control}_{stage}_{mark}_macs2_downSampled_peaks.narrowPeak",
    log:
        "output/logs/{case}_vs_{control}_{stage}_{mark}_call_peaks_macs2_downSampled.log"
    params:
        name = "{case}_vs_{control}_{stage}_{mark}_macs2_downSampled",
    shell:
        """ macs2 callpeak -f BAM -t {input.case} \
        -c {input.control} --keep-dup all \
        --outdir output/peaks/ -p 0.01 \
        -n {params.name} \
        -g mm 2> {log} """

rule call_peaks_macs2_pooled_replicates:
    input:
        E10 = "output/bam_files/E10.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E11 = "output/bam_files/E11.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E12 = "output/bam_files/E12.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E13 = "output/bam_files/E13.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E14 = "output/bam_files/E14.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E15 = "output/bam_files/E15.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
        E10C = "output/bam_files/input_E10.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E11C = "output/bam_files/input_E11.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E12C = "output/bam_files/input_E12.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E13C = "output/bam_files/input_E13.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E14C = "output/bam_files/input_E14.5_H3K27ac_downSampled_q30.sorted.dedup.bam",
        E15C = "output/bam_files/input_E15.5_H3K27ac_downSampled_q30.sorted.dedup.bam"
    output:
       "output/peaks/E10.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        "output/peaks/E11.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        "output/peaks/E12.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        "output/peaks/E13.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        "output/peaks/E14.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        "output/peaks/E15.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak"
    log:
        E10 = "output/qc/E10.5_H3K27ac.pooled.macs2_downSampled",
        E11 = "output/qc/E11.5_H3K27ac.pooled.macs2_downSampled",
        E12 = "output/qc/E12.5_H3K27ac.pooled.macs2_downSampled",
        E13 = "output/qc/E13.5_H3K27ac.pooled.macs2_downSampled",
        E14 = "output/qc/E14.5_H3K27ac.pooled.macs2_downSampled",
        E15 = "output/qc/E15.5_H3K27ac.pooled.macs2_downSampled"
    params:
        E10 = "E10.5_H3K27ac.pooled.macs2_downSampled",
        E11 = "E11.5_H3K27ac.pooled.macs2_downSampled",
        E12 = "E12.5_H3K27ac.pooled.macs2_downSampled",
        E13 = "E13.5_H3K27ac.pooled.macs2_downSampled",
        E14 = "E14.5_H3K27ac.pooled.macs2_downSampled",
        E15 = "E15.5_H3K27ac.pooled.macs2_downSampled"
    run:
        shell("macs2 callpeak -f BAM -t {input.E10} \
        -c {input.E10C} --keep-dup all \
        --outdir output/peaks/ -p 0.01 \
        -n {params.E10} \
        -g mm 2> {log.E10}" )
        shell("macs2 callpeak -f BAM -t {input.E11} \
        -c {input.E11C} --keep-dup all \
        --outdir output/peaks/ -p 0.01 \
        -n {params.E11} \
        -g mm 2> {log.E11}" )
        shell("macs2 callpeak -f BAM -t {input.E12} \
        -c {input.E12C} --keep-dup all \
        --outdir output/peaks/ -p 0.01 \
        -n {params.E12} \
        -g mm 2> {log.E12}" )
        shell("macs2 callpeak -f BAM -t {input.E13} \
        -c {input.E13C} --keep-dup all \
        --outdir output/peaks/ -p 0.01 \
        -n {params.E13} \
        -g mm 2> {log.E13}" )
        shell("macs2 callpeak -f BAM -t {input.E14} \
        -c {input.E14C} --keep-dup all \
        --outdir output/peaks/ -p 0.01 \
        -n {params.E14} \
        -g mm 2> {log.E14}" )
        shell("macs2 callpeak -f BAM -t {input.E15} \
        -c {input.E15C} --keep-dup all \
        --outdir output/peaks/ -p 0.01 \
        -n {params.E15} \
        -g mm 2> {log.E15}" )

# ===============================================================================================
#  8. Peak QC
#   > narrow peak counts
#   > fraction of reads in peaks (convert BAM to bed first then do intersect with peaks)
# ===============================================================================================

## Convert BAM to tagAlign file for calculating FRiP QC metric (Fraction of reads in peaks)
rule bamToBed:
    input:
        "output/bam_files/{case}_{stage}_{mark}_downSampled_q30.sorted.dedup.bam"
    output:
        "output/bam_files/{case}_{stage}_{mark}_downSampled_q30.sorted.dedup.bed"
    log:
        "output/logs/{case}_{stage}_{mark}_downSampled.bamToBed"
    shell:
        "samtools sort -n {input} | bedtools bamtobed -i - > {output}"

# ## Fraction of reads in peaks
rule frip:
    input:
        bed = "output/bam_files/{case}_{stage}_{mark}_downSampled_q30.sorted.dedup.bed",
        peak = "output/peaks/{case}_vs_{control}_{stage}_{mark}_macs2_downSampled_peaks.narrowPeak"
    output:
        "output/qc/{case}_vs_{control}_{stage}_{mark}_downSampled.frip.txt"
    shell:
        "python code/encode_frip.py {input.bed} {input.peak} > {output}"

# ===============================================================================================
#  9. Create consensus peaksets for replicates
# ===============================================================================================

# Based on ENCODE `overlap_peaks.py` - recommended for histone marks.
# Need to pool peaks first for each replicate

rule overlap_peaks:
    input:
        E10= ["output/peaks/ENCFF213EBC_vs_ENCFF157KEH_E10.5_H3K27ac_macs2_downSampled_peaks.narrowPeak", "output/peaks/ENCFF548BRR_vs_ENCFF825AVI_E10.5_H3K27ac_macs2_downSampled_peaks.narrowPeak"],
        E11= ["output/peaks/ENCFF512SFE_vs_ENCFF184CUE_E11.5_H3K27ac_macs2_downSampled_peaks.narrowPeak", "output/peaks/ENCFF515PKL_vs_ENCFF376FGM_E11.5_H3K27ac_macs2_downSampled_peaks.narrowPeak"],
        E12= ["output/peaks/ENCFF011NFM_vs_ENCFF058AUT_E12.5_H3K27ac_macs2_downSampled_peaks.narrowPeak", "output/peaks/ENCFF394TZN_vs_ENCFF203JQV_E12.5_H3K27ac_macs2_downSampled_peaks.narrowPeak"],
        E13= ["output/peaks/ENCFF194ORC_vs_ENCFF117QRC_E13.5_H3K27ac_macs2_downSampled_peaks.narrowPeak", "output/peaks/ENCFF290ZNF_vs_ENCFF248PGK_E13.5_H3K27ac_macs2_downSampled_peaks.narrowPeak"],
        E14= ["output/peaks/ENCFF902HAR_vs_ENCFF002HZV_E14.5_H3K27ac_macs2_downSampled_peaks.narrowPeak", "output/peaks/ENCFF327VAO_vs_ENCFF784ORI_E14.5_H3K27ac_macs2_downSampled_peaks.narrowPeak"],
        E15= ["output/peaks/ENCFF707WKL_vs_ENCFF182XFG_E15.5_H3K27ac_macs2_downSampled_peaks.narrowPeak", "output/peaks/ENCFF584JFB_vs_ENCFF727QTS_E15.5_H3K27ac_macs2_downSampled_peaks.narrowPeak"],
        E10_pooled="output/peaks/E10.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        E11_pooled="output/peaks/E11.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        E12_pooled="output/peaks/E12.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        E13_pooled="output/peaks/E13.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        E14_pooled="output/peaks/E14.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
        E15_pooled="output/peaks/E15.5_H3K27ac.pooled.macs2_downSampled_peaks.narrowPeak",
    output:
        E10= "output/peaks/H3K27ac_E10.5_overlap.narrowPeak",
        E11= "output/peaks/H3K27ac_E11.5_overlap.narrowPeak",
        E12= "output/peaks/H3K27ac_E12.5_overlap.narrowPeak",
        E13= "output/peaks/H3K27ac_E13.5_overlap.narrowPeak",
        E14= "output/peaks/H3K27ac_E14.5_overlap.narrowPeak",
        E15= "output/peaks/H3K27ac_E15.5_overlap.narrowPeak"
    run:
        shell("python code/overlap_peaks.py {input.E10} {input.E10_pooled} {output.E10}")
        shell("python code/overlap_peaks.py {input.E11} {input.E11_pooled} {output.E11}")
        shell("python code/overlap_peaks.py {input.E12} {input.E12_pooled} {output.E12}")
        shell("python code/overlap_peaks.py {input.E13} {input.E13_pooled} {output.E13}")
        shell("python code/overlap_peaks.py {input.E14} {input.E14_pooled} {output.E14}")
        shell("python code/overlap_peaks.py {input.E15} {input.E15_pooled} {output.E15}")

rule overlap_frip:
    input:
      E10bam = "output/bam_files/E10.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
      E11bam = "output/bam_files/E11.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
      E12bam = "output/bam_files/E12.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
      E13bam = "output/bam_files/E13.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
      E14bam = "output/bam_files/E14.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
      E15bam = "output/bam_files/E15.5_H3K27ac_downSampled_q30.sorted.pooled.dedup.bam",
      E10bed = "output/peaks/H3K27ac_E10.5_overlap.narrowPeak",
      E11bed = "output/peaks/H3K27ac_E11.5_overlap.narrowPeak",
      E12bed = "output/peaks/H3K27ac_E12.5_overlap.narrowPeak",
      E13bed = "output/peaks/H3K27ac_E13.5_overlap.narrowPeak",
      E14bed = "output/peaks/H3K27ac_E14.5_overlap.narrowPeak",
      E15bed = "output/peaks/H3K27ac_E15.5_overlap.narrowPeak"
    output:
      E10bed = "output/qc/H3K27ac_E10.5_overlap.frip",
      E11bed = "output/qc/H3K27ac_E11.5_overlap.frip",
      E12bed = "output/qc/H3K27ac_E12.5_overlap.frip",
      E13bed = "output/qc/H3K27ac_E13.5_overlap.frip",
      E14bed = "output/qc/H3K27ac_E14.5_overlap.frip",
      E15bed = "output/qc/H3K27ac_E15.5_overlap.frip"
    run:
      shell("python code/encode_frip.py {input.E10bam} {input.E10bed} > {output.E10bed}")
      shell("python code/encode_frip.py {input.E11bam} {input.E11bed} > {output.E11bed}")
      shell("python code/encode_frip.py {input.E12bam} {input.E12bed} > {output.E12bed}")
      shell("python code/encode_frip.py {input.E13bam} {input.E13bed} > {output.E13bed}")
      shell("python code/encode_frip.py {input.E14bam} {input.E14bed} > {output.E14bed}")
      shell("python code/encode_frip.py {input.E15bam} {input.E15bed} > {output.E15bed}")