#! /usr/bin/env python

## Author: Laura E Cook, University of Melbourne
## Purpose: ChIP-seq pipeline for histone marks
## This workflow only works for paired-end sequencing reads
## This is run for dunnart ChIP-seq library subsampled to 10 million reads
    # 1. deepTools
    # 2. Call narrow peaks (MACS2)
    # 3. Peak QC
    # 4. Create consensus peaksets
    # 5. Present QC for raw read, alignment, peak-calling in MultiQC (this is still a work in progress)

#! /usr/bin/env python

configfile: "code/configs/config.yaml"
# Contains sample and genome information
# calls the SRR.txt file that contains the samples as either IP or control

import csv
import os

IPS = []
INPUTS = []
MARK = []

with open(config['SAMPLES'], "r") as f:
    reader = csv.reader(f, delimiter = ",")
    header = next(reader)
    for row in reader:
        IPS.append(row[0])
        INPUTS.append(row[1])
        MARK.append(row[2])
f.close()

## multiple samples may use the same control input files
unique_inputs = list(set(INPUTS))
#unique_marks = list(set(MARK))

## combine all samples
all_samples = IPS + unique_inputs

# ===============================================================================================
#        Output targets
# ===============================================================================================

rule all:
    input:
        "output/qc/multibamsum_downSampled.npz",
        "output/qc/multibamsum_downSampled.tab",
        "output/qc/pearsoncor_multibamsum_downSampled.png",
        "output/qc/pearsoncor_multibamsum_matrix_downSampled.txt",
        expand("output/qc/{sample}.SeqDepthNorm_downSampled.bw", sample=all_samples),
        "output/qc/multiBAM_fingerprint_downSampled.png",
        "output/qc/multiBAM_fingerprint_metrics_downSampled.txt",
        "output/qc/multiBAM_fingerprint_rawcounts_downSampled.txt",
        "output/qc/bamPEFragmentSize_hist_downSampled.png",
        "output/qc/bamPEFragmentSize_rawcounts_downSampled.tab",
        expand("output/peaks/{case}_vs_{control}_macs2_default_peaks_downSampled.narrowPeak", zip, case=IPS, control=INPUTS),
        expand("output/peaks/{case}_vs_{control}_macs2_default_peaks_downSampled.xls", zip, case=IPS, control=INPUTS),
        expand("output/peaks/{case}_vs_{control}_macs2_default_summits_downSampled.bed", zip, case=IPS, control=INPUTS),
        expand("output/qc/{case}-vs-{control}-narrowpeak-count_mqc_downSampled.json", zip, case=IPS, control=INPUTS),
        expand("output/bam_files/{case}_downSampled.bedpe", case=IPS),
        expand("output/logs/{case}_downSampled.bamToBed", case=IPS),
        expand("output/qc/{case}_vs_{control}_downSampled.frip_default.txt", case=IPS, control=INPUTS),
        "output/peaks/H3K4me3_pooled_macs2_default_peaks_downSampled.narrowPeak",
        "output/peaks/H3K27ac_pooled_macs2_default_peaks_downSampled.narrowPeak",
        "output/peaks/H3K4me3_overlap_default_downSampled.narrowPeak",
        "output/peaks/H3K27ac_overlap_default_downSampled.narrowPeak",
        "output/qc/H3K4me3_overlap_default_downSampled.frip",
        "output/qc/H3K27ac_overlap_default_downSampled.frip"

# ===============================================================================================
#  1. deepTools
#   > multiBAMsummary
#   > plotCorrelation
#   > plotFingerprint
#   > bamCoverage (read depth normalised bigWig files)
#   > plotCoverage
#   > bamPEFragmentSize
# ===============================================================================================

rule deeptools_summary:
    input:
        bam = expand(["output/bam_files/{sample}_downSampled.PPq30.sorted.dedup.bam"], sample=all_samples),
        bai = expand(["output/bam_files/{sample}_downSampled.PPq30.sorted.dedup.bai"], sample=all_samples)
    output:
        sum="output/qc/multibamsum_downSampled.npz",
        counts="output/qc/multibamsum_downSampled.tab"
    threads: 32
    log:
        "output/logs/multisummary_downSampled.deepTools"
    shell:
        """multiBamSummary bins \
        -p {threads} \
        -b {input.bam} \
        --centerReads \
        -out {output.sum} \
        --outRawCounts {output.counts} 2> {log}"""

rule deeptools_correlation:
    input: "output/qc/multibamsum_downSampled.npz"
    output:
        fig="output/qc/pearsoncor_multibamsum_downSampled.png",
        matrix="output/qc/pearsoncor_multibamsum_matrix_downSampled.txt"
    log:
        "output/logs/correlation_downSampled.deepTools"
    shell:
        """plotCorrelation \
        --corData {input} \
        --plotFile {output.fig} \
        --outFileCorMatrix {output.matrix} \
        --corMethod pearson \
        --whatToPlot heatmap \
        --skipZeros \
        --plotNumbers \
        --colorMap RdYlBu 2> {log}"""

rule deeptools_coverage:
    input:
        bam ="output/bam_files/{sample}_downSampled.PPq30.sorted.dedup.bam",
        bai ="output/bam_files/{sample}_downSampled.PPq30.sorted.dedup.bai"
    output:
        "output/qc/{sample}.SeqDepthNorm_downSampled.bw"
    log:
        "output/logs/{sample}_coverage_downSampled.deepTools"
    shell:
        """bamCoverage \
        --bam {input.bam} \
        --binSize 10 \
        --normalizeUsing RPGC \
        --effectiveGenomeSize 2740338543 \
        --extendReads \
        -o {output} 2> {log}"""

rule deeptools_fingerprint:
    input:
        bam = expand(["output/bam_files/{sample}_downSampled.PPq30.sorted.dedup.bam"], sample=all_samples),
        bai = expand(["output/bam_files/{sample}_downSampled.PPq30.sorted.dedup.bai"], sample=all_samples)
    output:
        fig="output/qc/multiBAM_fingerprint_downSampled.png",
        metrics="output/qc/multiBAM_fingerprint_metrics_downSampled.txt",
        rawcounts="output/qc/multiBAM_fingerprint_rawcounts_downSampled.txt"
    threads: 32
    log:
        "output/logs/fingerprint_downSampled.deepTools"
    shell:
        """plotFingerprint -p {threads} \
        -b {input.bam} \
        --plotFile {output.fig} \
        --outQualityMetrics {output.metrics} \
        --outRawCounts {output.rawcounts} \
        --minMappingQuality 30 \
        --skipZeros \
        --centerReads 2> {log}"""

rule deeptools_bamPEFragmentSize:
    input:
        bam = expand(["output/bam_files/{sample}_downSampled.PPq30.sorted.dedup.bam"], sample=all_samples),
        bai = expand(["output/bam_files/{sample}_downSampled.PPq30.sorted.dedup.bai"], sample=all_samples)
    output:
        fig="output/qc/bamPEFragmentSize_hist_downSampled.png",
        rawcounts="output/qc/bamPEFragmentSize_rawcounts_downSampled.tab"
    log:
        "output/logs/bamPEFragmentSize_downSampled.deepTools"
    shell:
        """bamPEFragmentSize \
        -hist {output.fig} \
        --outRawFragmentLengths {output.rawcounts} \
        -b {input.bam} 2> {log}"""

# ===============================================================================================
# 2. Call peaks (MACS2)
# ===============================================================================================

# peak calling for pair-end peaks
# effective genome size for dunnart genome calculated with khmer program (see README.md)

rule call_peaks_macs2:
    input:
        control = "output/bam_files/{control}_downSampled.PPq30.sorted.dedup.bam",
        case = "output/bam_files/{case}_downSampled.PPq30.sorted.dedup.bam"
    output:
        "output/peaks/{case}_vs_{control}_macs2_default_peaks_downSampled.xls",
        "output/peaks/{case}_vs_{control}_macs2_default_summits_downSampled.bed",
        "output/peaks/{case}_vs_{control}_macs2_default_peaks_downSampled.narrowPeak",
    log:
        "output/logs/{case}_vs_{control}_call_peaks_macs2_default_downSampled.log"
    params:
        name = "{case}_vs_{control}_macs2_default",
    shell:
        """macs2 callpeak -f BAMPE -t {input.case} \
        -c {input.control} --keep-dup all \
        --outdir results_10M/macs2/  \
        -n {params.name} \
        -g 2740338543 2> {log}"""

rule call_peaks_macs2_pooled_replicates:
    input:
        H3K4me3 = "output/bam_files/H3K4me3_pooled_downSampled.PPq30.sorted.dedup.bam",
        H3K27ac = "output/bam_files/H3K27ac_pooled_downSampled.PPq30.sorted.dedup.bam",
        input = "output/bam_files/input_pooled_downSampled.PPq30.sorted.dedup.bam"
    output:
        "output/peaks/H3K4me3_pooled_macs2_default_peaks_downSampled.xls",
        "output/peaks/H3K4me3_pooled_macs2_default_summits_downSampled.bed",
        "output/peaks/H3K4me3_pooled_macs2_default_peaks_downSampled.narrowPeak",
        "output/peaks/H3K27ac_pooled_macs2_default_peaks_downSampled.xls",
        "output/peaks/H3K27ac_pooled_macs2_default_summits_downSampled.bed",
        "output/peaks/H3K27ac_pooled_macs2_default_peaks_downSampled.narrowPeak"
    log:
        H3K4me3 ="output/logs/H3K4me3_pooled_call_peaks_macs2_default_downSampled.log",
        H3K27ac ="output/logs/H3K27ac_pooled_call_peaks_macs2_default_downSampled.log"
    params:
        H3K4me3 = "H3K4me3_pooled_macs2_default",
        H3K27ac = "H3K27ac_pooled_macs2_default"
    run:
        shell("macs2 callpeak -f BAMPE -t {input.H3K4me3} \
        -c {input.input} --keep-dup all \
        --outdir results_10M/macs2/ \
        -n {params.H3K4me3} \
        -g 2740338543 2> {log.H3K4me3}")
        shell("macs2 callpeak -f BAMPE -t {input.H3K27ac} \
        -c {input.input} --keep-dup all \
        --outdir results_10M/macs2/ -p 0.01 \
        -n {params.H3K27ac} \
        -g 2740338543 2> {log.H3K27ac}")

# ===============================================================================================
#  3. Peak QC
#   > narrow peak counts
#   > fraction of reads in peaks (convert BAM to bed first then do intersect with peaks)
# ===============================================================================================

# peak counts in a format that multiqc can handle
rule get_narrow_peak_counts_for_multiqc:
    input:
        peaks = "output/peaks/{case}_vs_{control}_macs2_peaks_downSampled.narrowPeak"
    output:
        "output/qc/{case}-vs-{control}-narrowpeak-count_mqc_downSampled.json"
    params:
        peakType = "narrowPeak"
    shell:
        """python3 scripts/count_peaks.py \
        --peak_type {params.peakType} \
        --peaks {input.peaks} --sample_name {wildcards.case} > {output}"""


## Convert BAM to tagAlign file for calculating FRiP QC metric (Fraction of reads in peaks)
rule bamToBed:
    input:
        "output/bam_files/{case}_downSampled.PPq30.sorted.dedup.bam"
    output:
        "output/bam_files/{case}_downSampled.bedpe"
    log:
        "output/logs/{case}_downSampled.bamToBed"
    shell:
        "samtools sort -n {input} | bedtools bamtobed -bedpe -mate1 -i - > {output}"


## Fraction of reads in peaks
rule frip:
    input:
        bed = "output/bam_files/{case}_downSampled.bedpe",
        peak = "output/peaks/{case}_vs_{control}_macs2_default_peaks_downSampled.narrowPeak"
    output:
        "output/qc/{case}_vs_{control}.frip_default_downSampled.txt"
    shell:
        "python2.7 scripts/encode_frip.py {input.bed} {input.peak} > {output}"


# ===============================================================================================
#  4. Create consensus peaksets for replicates
# ===============================================================================================

# Based on ENCODE `overlap_peaks.py` - recommended for histone marks.
# Need to pool peaks first for each replicate

rule overlap_peaks_H3K4me3:
    input:
        peak1="output/peaks/A-2_H3K4me3_vs_A-1_input_macs2_default_peaks_downSampled.narrowPeak",
        peak2="output/peaks/B-2_H3K4me3_vs_B-1_input_macs2_default_peaks_downSampled.narrowPeak",
        pooled="output/peaks/H3K4me3_pooled_macs2_default_peaks_downSampled.narrowPeak"
    output:
        "output/peaks/H3K4me3_overlap_default_downSampled.narrowPeak"
    shell:
        "python2.7 scripts/overlap_peaks.py {input.peak1} {input.peak2} {input.pooled} {output}"


rule overlap_peaks_H3K27ac:
    input:
        peak1="output/peaks/A-3_H3K27ac_vs_A-1_input_macs2_default_peaks_downSampled.narrowPeak",
        peak2="output/peaks/B-3_H3K27ac_vs_B-1_input_macs2_default_peaks_downSampled.narrowPeak",
        pooled="output/peaks/H3K27ac_pooled_macs2_default_peaks_downSampled.narrowPeak"
    output:
        "output/peaks/H3K27ac_overlap_default_downSampled.narrowPeak"
    shell:
        "python2.7 scripts/overlap_peaks.py {input.peak1} {input.peak2} {input.pooled} {output}"

## Fraction of reads in peaks
rule overlap_frip:
    input:
        H3K4me3bam = "output/bam_files/H3K4me3_pooled_downSampled.PPq30.sorted.dedup.bam",
        H3K27acbam = "output/bam_files/H3K27ac_pooled_downSampled.PPq30.sorted.dedup.bam",
        H3K4me3bed = "output/peaks/H3K4me3_overlap_default_downSampled.narrowPeak",
        H3K27acbed = "output/peaks/H3K27ac_overlap_default_downSampled.narrowPeak"
    output:
        H3K4me3frip = "output/qc/H3K4me3_overlap_default_downSampled.frip",
        H3K27acfrip = "output/qc/H3K27ac_overlap_default_downSampled.frip"
    run:
        shell("python2.7 scripts/encode_frip.py {input.H3K4me3bam} {input.H3K4me3bed} > {output.H3K4me3frip}")
        shell("python2.7 scripts/encode_frip.py {input.H3K27acbam} {input.H3K27acbed} > {output.H3K27acfrip}")